---
layout: post
title: Redis Performance - Does key length matter?
date: 2012-11-15 08:00:41.000000000 -06:00
categories:
- nodejs
- nodejs
tags:
- coffeescript
- nodejs
- NoSQL
- redis
status: publish
type: post
published: true
author: Adam N England
---
I'm currently building a project using <a href="http://redis.io/">redis</a> as a high performance cache in a node.js application (using the excellent <a href="https://github.com/mranney/node_redis">node_redis</a>). My key values will be fairly large ( between 512b and 1kb). The Redis documentation doesn't specifically warn against keys of this size, but it still seems appropriate to do a benchmark, and see how Redis reacts to large keys (and whether or not 1k is really a <strong>large</strong> key, or just par for the course).

<span style="text-decoration:underline;"><strong>Test Script</strong></span><strong> </strong>(<a href="https://gist.github.com/4076309">source</a>)

Basically, we insert 1000 records into redis, each with a 10,000 character value. After the writes are all complete, we read each key back from redis.

{% highlight javascript linenos %}
redis = require "redis"
randomString = (length) ->
  chars = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'
  result = ""
  i = length
  while i > 0
    result += chars[Math.round(Math.random() * (chars.length - 1))]
    --i
  result
writeTest = (keyLength) ->
	console.log "1000 set statements for #{keyLength} character keys"
	keys = []
	for x in [1..1000]
		keys.push randomString(keyLength)
	startTime = new Date().getTime()
	for x in keys
		client.set x, randomString(10000)
	client.quit ->
		console.log "1000 keys inserted in #{new Date().getTime() - startTime} ms"
		readTest(keys)
readTest = (keys) ->
	client = redis.createClient()
	startTime = new Date().getTime()
	for x in keys
		client.get x
	client.quit ->
		console.log "1000 keys retreived in #{new Date().getTime() - startTime} ms"</p>
client = redis.createClient()
client.flushdb ->
	writeTest(20000)
{% endhighlight %}

This test was performed for key lengths of 10, 100, 500, 1000, 2500, 5000, 7500, 10,000, and 20,000 characters. Three runs of each were performed to avoid any fluke results. Without further ado, the results.

<span style="text-decoration:underline;"><strong>Write Performance (in ms)</strong></span>

<table style="border:1px solid black;">
<tbody>
<tr style="border:1px solid black;">
<th>Key Length</th>
<th>Run 1</th>
<th>Run 2</th>
<th>Run 3</th>
</tr>
<tr style="border:1px solid black;">
<td>10</td>
<td>1235</td>
<td>1216</td>
<td>1259</td>
<td></td>
</tr>
<tr style="border:1px solid black;">
<td>100</td>
<td>1231</td>
<td>1242</td>
<td>1223</td>
</tr>
<tr style="border:1px solid black;">
<td>500</td>
<td>1283</td>
<td>1240</td>
<td>1270</td>
</tr>
<tr style="border:1px solid black;">
<td>1000</td>
<td>1277</td>
<td>1317</td>
<td>1345</td>
</tr>
<tr style="border:1px solid black;">
<td>2500</td>
<td>1318</td>
<td>1279</td>
<td>1294</td>
</tr>
<tr style="border:1px solid black;">
<td>5000</td>
<td>1376</td>
<td>1391</td>
<td>1386</td>
</tr>
<tr style="border:1px solid black;">
<td>7500</td>
<td>1223</td>
<td>1204</td>
<td>1265</td>
</tr>
<tr style="border:1px solid black;">
<td>10000</td>
<td>1220</td>
<td>1252</td>
<td>1235</td>
</tr>
<tr style="border:1px solid black;">
<td>20000</td>
<td>2065</td>
<td>2014</td>
<td>2016</td>
</tr>
</tbody>
</table>
<p><span style="text-decoration:underline;"><strong>Read Performance (in ms)</strong></span></p>
<table style="border:1px solid black;">
<tbody>
<tr style="border:1px solid black;">
<th>Key Length</th>
<th>Run 1</th>
<th>Run 2</th>
<th>Run 3</th>
</tr>
<tr style="border:1px solid black;">
<td>10</td>
<td>43</td>
<td>41</td>
<td>51</td>
</tr>
<tr style="border:1px solid black;">
<td>100</td>
<td>45</td>
<td>45</td>
<td>43</td>
</tr>
<tr style="border:1px solid black;">
<td>500</td>
<td>60</td>
<td>54</td>
<td>58</td>
</tr>
<tr style="border:1px solid black;">
<td>1000</td>
<td>69</td>
<td>73</td>
<td>79</td>
</tr>
<tr style="border:1px solid black;">
<td>2500</td>
<td>97</td>
<td>101</td>
<td>102</td>
</tr>
<tr style="border:1px solid black;">
<td>5000</td>
<td>113</td>
<td>114</td>
<td>110</td>
</tr>
<tr style="border:1px solid black;">
<td>7500</td>
<td>134</td>
<td>133</td>
<td>136</td>
</tr>
<tr style="border:1px solid black;">
<td>10000</td>
<td>147</td>
<td>156</td>
<td>151</td>
</tr>
<tr style="border:1px solid black;">
<td>20000</td>
<td>244</td>
<td>234</td>
<td>241</td>
</tr>
</tbody>
</table>
<p>Not surprisingly, as the key length increases, times do increase.  However, write times are relatively unaffected by key length, while read times seem to be impacted more.   To put it in perspective:</p>
<ul>
<li>Key length 10 - an average write takes 1.24ms, an average read takes 0.045ms</li>
<li>Key length 10,000 - an average write takes 1.24ms, an average read takes 0.15ms</li>
</ul>
<p>Whether or not this is significant is really up to you, however, for my purposes, it seems like an insignificant difference.  At the end of the day, redis is a fast and flexible tool for caching data.</p>
